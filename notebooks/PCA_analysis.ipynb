{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run './feature_engineering.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Vectorize the features\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "\"\"\"\n",
    "Running PCA against the features used in Multi-class Classification: [multi_class logistisc regression](notebooks/regression-model-stations-to-bike-type.ipynb)\n",
    "Filtering by workdays to reduce the data size and improve the model's performance\n",
    "The Logistic Regression model\n",
    "    labelCol: rideable_type_index\n",
    "    features = ['day_period_index', 'start_station_id_index', 'end_station_id_index']\n",
    "    rideable_type - 0: classic_bike, 1: docked_bike, 2: electric_bike\n",
    "We'll discard the docked_bike type as it's not relevant for the predictive analysis of the number of bikes needed at each station at different times of the day.\n",
    "\"\"\"\n",
    "\n",
    "sampled_df_with_added_features_indexed = sampled_df_with_added_features_indexed.filter(sampled_df_with_added_features['rideable_type'] != 'docked_bike')\n",
    "\n",
    "df_workdays = sampled_df_with_added_features_indexed.filter(sampled_df_with_added_features_indexed['week_day'] == 'Workday')\n",
    "features = ['day_period_index', 'start_station_id_index', 'end_station_id_index', 'rideable_type_index']\n",
    "\n",
    "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "# # Scaling the features\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=False)\n",
    "\n",
    "# # Combine the VectorAssembler and StandardScaler into a Pipeline\n",
    "from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# You can now define a pipeline that includes both the assembler and the scaler\n",
    "pipeline = Pipeline(stages=[assembler, scaler])\n",
    "\n",
    "# Fit and transform the DataFrame using the defined pipeline\n",
    "sampled_df_scaled = pipeline.fit(sampled_df_with_added_features_indexed).transform(\n",
    "    sampled_df_with_added_features_indexed)\n",
    "\n",
    "from pyspark.ml.feature import PCA\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(k=4, inputCol=\"scaled_features\", outputCol=\"pca_features\")\n",
    "pca_model = pca.fit(sampled_df_scaled)\n",
    "pca_result = pca_model.transform(sampled_df_scaled)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Extract the PCA loadings\n",
    "loadings = pca_model.pc.toArray()\n",
    "\n",
    "# For visualization, ensure we have the correct shape: components x features\n",
    "print(loadings.shape)  # Should be (n_components, n_features)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(loadings, annot=True, cmap='inferno', yticklabels=[f'PC{i+1}' for i in range(loadings.shape[0])], xticklabels=features)\n",
    "plt.title('PCA Loadings Heatmap')\n",
    "plt.ylabel('Principal Components')\n",
    "plt.xlabel('Features')\n",
    "plt.savefig(os.path.join(images_path, 'heatmap_PCA_model_features.png'))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca_pd['PC1'] = pca_pd['pca_features'].apply(lambda x: x[0])\n",
    "pca_pd['PC2'] = pca_pd['pca_features'].apply(lambda x: x[1])\n",
    "pca_pd['PC3'] = pca_pd['pca_features'].apply(lambda x: x[2])\n",
    "pca_pd['PC4'] = pca_pd['pca_features'].apply(lambda x: x[3])\n",
    "pca_pd['PC5'] = pca_pd['pca_features'].apply(lambda x: x[4])\n",
    "pca_pd['PC6'] = pca_pd['pca_features'].apply(lambda x: x[5])\n",
    "pd_scatter = pd.DataFrame(pca_pd, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6'])\n",
    "\n",
    "features = ['day_period_index', 'start_station_id_index', 'end_station_id_index']\n",
    "# Plotting PCA results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(pca_pd['PC5'], pca_pd['PC6'], cmap='inferno')\n",
    "plt.title('PCA: First vs. Second Principal Component')\n",
    "plt.xlabel('Principal Component 1 (PC5)')\n",
    "plt.ylabel('Principal Component 2 (PC6)')\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(images_path, 'pca_scatter_plot_PC5_and_PC6.png'))\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #Plot a Correlation matrix of the features before applying PCA\n",
    "import seaborn as sns\n",
    "pd_sampled_df = sampled_df_with_added_features_indexed.toPandas()\n",
    "\n",
    "# Plotting correlation matrix of the features\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "corr = pd_sampled_df[features].corr()\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='inferno', linewidth=.5, cbar=True, square=True)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig(os.path.join(images_path, 'selected_features_correlation_matrix.png'))\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
