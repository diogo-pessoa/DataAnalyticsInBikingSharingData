{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Data exploration\n",
    "\n",
    "Section dedicated to exploring the data and validating the added features. Using Visualizations to understand the aggregated data and the relationships between the chosen features."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%run './feature_engineering.ipynb'\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Most popular Stations (Start & End) By Working Day and Day Period\n",
    "# Stations with most demand for Eletric bikes by working day and day period\n",
    "# Non-Workdays Stations patterns for rideable types\n",
    "# Non-Workdays Stations patterns for member_casual\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #Plot a Correlation matrix of the features before applying PCA\n",
    "import seaborn as sns\n",
    "pd_sampled_df = sampled_df_with_added_features_indexed.toPandas()\n",
    "\n",
    "# Plotting correlation matrix of the features\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "corr = pd_sampled_df[features].corr()\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='inferno', linewidth=.5, cbar=True, square=True)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig(os.path.join(images_path, 'selected_features_correlation_matrix.png'))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "# Group by 'start_station_id' and count\n",
    "start_overall_station_counts = sampled_df_with_added_features.groupBy('start_station_name').count()\n",
    "end_overall_station_counts = sampled_df_with_added_features.groupBy('end_station_name').count()\n",
    "\n",
    "# most popular routes start to end stations by day of week\n",
    "# Group by 'start_station_name', 'end_station_name', 'week_day' and count\n",
    "start_end_week_day_station_counts = sampled_df_with_added_features.groupBy('start_station_name', 'end_station_name',\n",
    "                                                                           'week_day').count()\n",
    "# most popular routes start to end stations by day of week and time of day\n",
    "# Group by 'start_station_name', 'end_station_name', 'week_day', 'day_period' and count\n",
    "start_end_week_day_period_station_counts = sampled_df_with_added_features.groupBy('start_station_name', 'end_station_name',\n",
    "                                                                                  'week_day', 'day_period').count()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 6\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;124;03mConverting to Pandas DataFrame to load into seaborn for plotting.\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03mNote I'm only converting to Pandas after the PySpark aggregations, aware of the performance implications in larger datasets.\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      5\u001B[0m end_overall_station_counts_pandas \u001B[38;5;241m=\u001B[39m end_overall_station_counts\u001B[38;5;241m.\u001B[39mtoPandas()\n\u001B[0;32m----> 6\u001B[0m start_overall_station_counts_pandas \u001B[38;5;241m=\u001B[39m \u001B[43mstart_overall_station_counts\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtoPandas\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m start_end_week_day_station_counts_pandas \u001B[38;5;241m=\u001B[39m start_end_week_day_station_counts\u001B[38;5;241m.\u001B[39mtoPandas()\n\u001B[1;32m      8\u001B[0m start_end_week_day_period_station_counts_pandas \u001B[38;5;241m=\u001B[39m start_end_week_day_period_station_counts\u001B[38;5;241m.\u001B[39mtoPandas()\n",
      "File \u001B[0;32m~/code/TechProject1/venv/lib/python3.9/site-packages/pyspark/sql/pandas/conversion.py:202\u001B[0m, in \u001B[0;36mPandasConversionMixin.toPandas\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    199\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[1;32m    201\u001B[0m \u001B[38;5;66;03m# Below is toPandas without Arrow optimization.\u001B[39;00m\n\u001B[0;32m--> 202\u001B[0m rows \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    203\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(rows) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    204\u001B[0m     pdf \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame\u001B[38;5;241m.\u001B[39mfrom_records(\n\u001B[1;32m    205\u001B[0m         rows, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(rows)), columns\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[1;32m    206\u001B[0m     )\n",
      "File \u001B[0;32m~/code/TechProject1/venv/lib/python3.9/site-packages/pyspark/sql/dataframe.py:1257\u001B[0m, in \u001B[0;36mDataFrame.collect\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1237\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Returns all the records as a list of :class:`Row`.\u001B[39;00m\n\u001B[1;32m   1238\u001B[0m \n\u001B[1;32m   1239\u001B[0m \u001B[38;5;124;03m.. versionadded:: 1.3.0\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1254\u001B[0m \u001B[38;5;124;03m[Row(age=14, name='Tom'), Row(age=23, name='Alice'), Row(age=16, name='Bob')]\u001B[39;00m\n\u001B[1;32m   1255\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1256\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m SCCallSiteSync(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sc):\n\u001B[0;32m-> 1257\u001B[0m     sock_info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollectToPython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1258\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n",
      "File \u001B[0;32m~/code/TechProject1/venv/lib/python3.9/site-packages/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1314\u001B[0m args_command, temp_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_args(\u001B[38;5;241m*\u001B[39margs)\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[0;32m-> 1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_command\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommand\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n\u001B[1;32m   1323\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
      "File \u001B[0;32m~/code/TechProject1/venv/lib/python3.9/site-packages/py4j/java_gateway.py:1038\u001B[0m, in \u001B[0;36mGatewayClient.send_command\u001B[0;34m(self, command, retry, binary)\u001B[0m\n\u001B[1;32m   1036\u001B[0m connection \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_connection()\n\u001B[1;32m   1037\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1038\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_command\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommand\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1039\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m binary:\n\u001B[1;32m   1040\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m response, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_connection_guard(connection)\n",
      "File \u001B[0;32m~/code/TechProject1/venv/lib/python3.9/site-packages/py4j/clientserver.py:511\u001B[0m, in \u001B[0;36mClientServerConnection.send_command\u001B[0;34m(self, command)\u001B[0m\n\u001B[1;32m    509\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    510\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 511\u001B[0m         answer \u001B[38;5;241m=\u001B[39m smart_decode(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m    512\u001B[0m         logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAnswer received: \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(answer))\n\u001B[1;32m    513\u001B[0m         \u001B[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001B[39;00m\n\u001B[1;32m    514\u001B[0m         \u001B[38;5;66;03m# answer before the socket raises an error.\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/Cellar/python@3.9/3.9.18_2/Frameworks/Python.framework/Versions/3.9/lib/python3.9/socket.py:704\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    702\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    703\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 704\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    706\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Converting to Pandas DataFrame to load into seaborn for plotting.\n",
    "Note I'm only converting to Pandas after the PySpark aggregations, aware of the performance implications in larger datasets.\n",
    "\"\"\"\n",
    "end_overall_station_counts_pandas = end_overall_station_counts.toPandas()\n",
    "start_overall_station_counts_pandas = start_overall_station_counts.toPandas()\n",
    "start_end_week_day_station_counts_pandas = start_end_week_day_station_counts.toPandas()\n",
    "start_end_week_day_period_station_counts_pandas = start_end_week_day_period_station_counts.toPandas()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# start_end_week_day_station_counts_plot = start_end_week_day_station_counts_pandas\n",
    "start_end_week_day_day_period_station_counts_plot =  start_end_week_day_period_station_counts_pandas\n",
    "top_10_start_stations = start_overall_station_counts_pandas\n",
    "top_10_end_stations = start_overall_station_counts_pandas\n",
    "# plot top ten stations, end. By day period.\n",
    "# Further explore the correlation start end, by day period, filtering by week day.\n",
    "# Plot a Correlation matrix of the features before applying PCA\n",
    "# TODO -  Stick to the fact that the goal in this project is to optimize the service to restock the stations, avoiding empty stations or users waiting to dock the bikes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# concat top_10_start_stations and top_10_end_stations to plot the most popular stations\n",
    "top_10_start_stations = top_10_start_stations.nlargest(10, 'count')\n",
    "top_10_end_stations = top_10_end_stations.nlargest(10, 'count')\n",
    "top_10_end_stations.head(5)\n",
    "\n",
    "# top_10_combined = pd.merge([top_10_start_stations, top_10_end_stations], right='start_station_name', left='end_station_name')\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create the barplot\n",
    "sns.barplot(x='Station Name', y='Count', hue='Type', data=top_10_combined, palette='viridis')\n",
    "\n",
    "plt.title('Most Popular Start and End Stations')\n",
    "plt.xlabel('Station Name')\n",
    "plt.ylabel('Count of Trips')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Trip Type')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the plot to TechReport images folder\n",
    "plt.savefig(os.path.join(images_path, 'count_most_popular_start_stations.png'))\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
